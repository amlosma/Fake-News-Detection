{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "liarplus.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smara97/FakeNews/blob/master/liarplus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg8QmECF_eHE",
        "colab_type": "code",
        "outputId": "33e1f61a-19a0-4715-c1e2-8bc2a86a9041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from google.colab import files,drive\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import wordpunct_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from torch.autograd import Variable\n",
        "from string import punctuation\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import collections\n",
        "import nltk\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import string\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k39R3AAAADa8",
        "colab_type": "code",
        "outputId": "24c90970-3b17-46b9-cbdb-596b33e81540",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3HBqw4Onjsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Model to Training Data \n",
        "\n",
        "  Forward Function\n",
        "Take length of Embedding and Dim of it and Create Embedding Layer by torch Framework\n",
        "Create Neural Network Layer take 903 input and return 256 as output layer\n",
        "then bass output to non-activation function layer then add dropout to output\n",
        "bass output to Linear take 256 and return number of class 1 and then add sigmoid to output\n",
        "\n",
        "  Conv Function \n",
        "Take inputs ( self, inputs layer[batch size of training inputs*Featuers] (64,1440) )\n",
        "\n",
        "conv inputs layer from [64,1440] to [64,903]\n",
        "\n",
        "first 300s number repersent the vector sentence(Statement) of Embedding\n",
        "\n",
        "301 add Similarity of Statement Featuer (first [410] numbers of orignal input) and \n",
        "  Subject Featuer (second [30] numbers of orignal input)\n",
        "\n",
        "from 302 to 602 add number repersent the vector sentence(Subject) of Embedding\n",
        "\n",
        "602 add Similarity of Subject Featuer ([30] numbers of orignal input) and \n",
        "  Justification Featuer (second [1000] numbers of orignal input)\n",
        "\n",
        "from 602 to 902 add number repersent the vector sentence(Justifaction) of Embedding\n",
        "\n",
        "903 add Similarity of Justification Featuer ([100] numbers of orignal input) and \n",
        "  Statement Featuer (second [410] numbers of orignal input)\n",
        "\n",
        "and return [64,903]\n",
        "\n",
        "Then Pass output of Conv to Forward\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class NN(nn.Module):\n",
        "\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_dim,word_embedding):\n",
        "\n",
        "    super(NN, self).__init__()\n",
        "\n",
        "        \n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)   \n",
        "    self.embedding.weight.data.copy_(word_embedding)\n",
        "    self.lstm = nn.LSTM(903, 128, 2, dropout=0.6, batch_first=True)\n",
        "    self.fc = nn.Linear(128,1)\n",
        "    self.dropout=nn.Dropout(0.5)\n",
        "    self.sig = nn.Sigmoid()\n",
        "\n",
        "\n",
        "  def forward(self, x,hidden):\n",
        "\n",
        "    batch_size = x.size(0)\n",
        "\n",
        "    x = self.conv(x)\n",
        "    \n",
        "\n",
        "    lstm_out, hidden = self.lstm(x, hidden)\n",
        "    lstm_out = lstm_out.contiguous().view(-1,128)\n",
        "    out = self.dropout(lstm_out)\n",
        "    out=self.sig(self.fc(out))\n",
        "    sig_out = out.view(batch_size, -1)\n",
        "    sig_out = sig_out[:, -1]\n",
        "    return sig_out, hidden\n",
        "    \n",
        "  def conv(self,x):\n",
        "    batch=len(x)\n",
        "\n",
        "    ret=torch.zeros((batch,903)).cuda()\n",
        "    st=torch.zeros(300).cuda()\n",
        "    su=torch.zeros(300).cuda()\n",
        "    ju=torch.zeros(300).cuda()\n",
        "\n",
        "\n",
        "    \n",
        "    for i in range(batch):\n",
        "  \n",
        "      st=self.embedding(x[i][0:411]).sum(dim=0)/(x[i][0:411]!=0).sum()\n",
        "      su=self.embedding(x[i][411:441]).sum(dim=0)/(x[i][411:441]!=0).sum()\n",
        "      ju=self.embedding(x[i][441:1440]).sum(dim=0)/(x[i][441:1440]!=0).sum()\n",
        "      \n",
        "      ret[i][:300]=st\n",
        "      ret[i][300]=simlarity(st,su)\n",
        "\n",
        "      ret[i][301:601]=su\n",
        "      ret[i][601]=simlarity(su,ju)\n",
        "\n",
        "      ret[i][602:902]=ju\n",
        "      \n",
        "      ret[i][902]=simlarity(st,ju)\n",
        "    return ret.view(1,batch,903)\n",
        "  def init_hidden(self, batch_size):\n",
        "    weight = next(self.parameters()).data\n",
        "    hidden = (weight.new(2, 1, 128).zero_().cuda(),\n",
        "                  weight.new(2, 1, 128).zero_().cuda())\n",
        "    return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LpKF7Bj6Hw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        " Read Glove File take url of file return the two dictionaries ( word to index and word to vector in embedding )\n",
        " and one list of index to word  \n",
        " (glove file url) --> words_to_index, index_to_words, word_to_vec_map\n",
        " \n",
        " \"\"\"\n",
        "\n",
        "def read_glove_vecs(glove_file):\n",
        "    with open(glove_file, 'r',encoding='UTF-8') as f:\n",
        "        words = set()\n",
        "        word_to_vec_map = {}\n",
        "        for line in f:\n",
        "            line = line.strip().split()\n",
        "            curr_word = line[0]\n",
        "            words.add(curr_word)\n",
        "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
        "        \n",
        "        i = 1\n",
        "        words_to_index = {}\n",
        "        index_to_words = {}\n",
        "        for w in sorted(words):\n",
        "            words_to_index[w] = i\n",
        "            index_to_words[i] = w\n",
        "            i = i + 1\n",
        "    return words_to_index, index_to_words, word_to_vec_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_YGt1t36NVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Word Embeddings of words take dictionary of word to embedding and word to index\n",
        "and return Embeddings Matrix [index,Embedding] \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
        "    vocab_len = len(word_to_index) + 1\n",
        "    emb_matrix = np.zeros((vocab_len,300))\n",
        "    for word, index in word_to_index.items():\n",
        "        emb_matrix[index, :] = word_to_vec_map[word]\n",
        "    return emb_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG5u2iTih9ID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Clean Text \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def clean(text):\n",
        "  text=text.lower()\n",
        "  stp=set(stopwords.words(\"english\"))\n",
        "  placesp = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "  removech= re.compile('[^0-9a-z #+_]')\n",
        "  st=WordNetLemmatizer()\n",
        "  text=re.sub(placesp,' ',text)\n",
        "  text=re.sub(removech,' ',text)\n",
        "  text=text.split()\n",
        "  text=[w for w in text if not w in stp]\n",
        "  text=[st.lemmatize(w) for w in text]\n",
        "  text=\" \".join(text)\n",
        "  text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyXAjL26LJxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Transfer sentence to indeces word in Embedding\n",
        "take text and word to index dictionary \n",
        "return list of indeces word in Embedding\n",
        "\n",
        "\"\"\"\n",
        "def transfer_sent(text,word_to_index):\n",
        "  text=text.split(' ')\n",
        "  ret=[]\n",
        "  for w in text:\n",
        "    if w in word_to_index and w !=\"\":\n",
        "      ret.append(word_to_index[w])\n",
        "  return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAFkt1gUUIkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Similarity of two Documnets \n",
        "take two documnets\n",
        "return The Similarity of documents\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def simlarity(dim1,dim2):\n",
        "  return (torch.dot(dim1,dim2)/(torch.sqrt(torch.sum(dim1**2))*torch.sqrt(torch.sum(dim2**2))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owt9-oD4iutn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Accuracy of predict labels\n",
        "take predict labels and target labels\n",
        "return number of accept label in predict labels\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def Accu(pred,labels):\n",
        "  ret=0\n",
        "  for i in range(len(labels)):\n",
        "    if pred[i]==labels[i]:\n",
        "      ret+=1\n",
        "  return ret/len(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N6FmfbWRwwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "calculate the Max Length in every column in Data Frame \n",
        "take Data Frame \n",
        "return Max lenght of columns\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def retmax(dftrain):\n",
        "\n",
        "  stmax,sumax,jumax=0,0,0\n",
        "  for i in range(dftrain.shape[0]):\n",
        "\n",
        "    stmax=max(stmax,len(np.array(dftrain.loc[i,'statement'])))\n",
        "\n",
        "    sumax=max(sumax,len(np.array(dftrain.loc[i,'subject'])))\n",
        "\n",
        "    jumax=max(jumax,len(np.array(dftrain.loc[i,'justification'])))\n",
        "\n",
        "  return stmax,sumax,jumax\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GG5byD7ZbBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Convert Data Frame to Matrix 2D by Adding padding zeros to every columns that not have lenght not equal max\n",
        "lenght.\n",
        "take Data Frame list of Max Lenghts of Columns\n",
        "return Matrix after convert\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def convert2D(Xs,max_lens):\n",
        "   X_indices = np.zeros((Xs[0].shape[0], sum(max_lens)))\n",
        "   pls=0\n",
        "\n",
        "   for i in range(Xs[0].shape[0]):\n",
        "     pls=0\n",
        "     \n",
        "     for j in range(0,len(Xs[0][i])):\n",
        "       X_indices[i][j+pls]=Xs[0][i][j]\n",
        "     pls=max_lens[0]\n",
        "\n",
        "     for j in range(0,len(Xs[1][i])):\n",
        "       X_indices[i][j+pls+1]=Xs[1][i][j]\n",
        "     pls=max_lens[1]+max_lens[0]\n",
        "\n",
        "     for j in range(0,len(Xs[2][i])):\n",
        "       X_indices[i][j+pls+1]=Xs[2][i][j]\n",
        "   return X_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C7Ej5cQNHUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "convert labels to 0,1 True or False  \n",
        "\n",
        "\"\"\"\n",
        "convertlabel = {\n",
        "\t'pants-fire': 0,\n",
        "\t'false': 0,\n",
        "\t'barely-true': 0,\n",
        "\t'half-true': 1,\n",
        "\t'mostly-true': 1,\n",
        "\t'true': 1\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvDjhEJ5AuqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "list of columns's Name \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "cols=['index','ID','label','statement','subject','speaker',\n",
        "      'speaker_job','state','party','barely_true',\n",
        "      'false','half_true','mostly_true','pants_on_fire',\n",
        "      'context','justification']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmu1XWkeJ3gW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Call read_glove_vecs function and then call pretrained_embedding_layer to calc word Embedding of Words\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs(\"/content/drive/My Drive/Datasets/Word Embedding/glove.6B.300d.txt\")\n",
        "word_embedding=pretrained_embedding_layer(word_to_vec_map, word_to_index)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI1wca7kAHbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Read Dataset (Data Frame)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "dftrain=pd.read_csv(\"/content/drive/My Drive/Datasets/liar-plus/train.tsv\",sep=\"\\t\",header=None)\n",
        "dfval=pd.read_csv(\"/content/drive/My Drive/Datasets/liar-plus/val.tsv\",sep=\"\\t\",header=None)\n",
        "dftest=pd.read_csv(\"/content/drive/My Drive/Datasets/liar-plus/test.tsv\",sep=\"\\t\",header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8jZpxs8CIrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Add list cols to Data Frame columns\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "dftrain.columns=cols\n",
        "dfval.columns=cols\n",
        "dftest.columns=cols"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCo9SEQ6SiQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Make Datasets have only statement,subject,justification and label \n",
        "important Feauters to Training\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "dftrain=dftrain.loc[:,['statement','subject','justification','label']]\n",
        "dfval=dfval.loc[:,['statement','subject','justification','label']]\n",
        "dftest=dftest.loc[:,['statement','subject','justification','label']]\n",
        "dftrain=dftrain.append(dfval)\n",
        "dftrain=dftrain.append(dftest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiytTGihAnEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Drop NAN value and index column in Datasets \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "dftrain=dftrain.dropna(axis=0)\n",
        "\n",
        "dftrain=dftrain.reset_index()\n",
        "\n",
        "dftrain=dftrain.drop(['index'],axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlwxZGVZMi54",
        "colab_type": "code",
        "outputId": "803d452c-118f-44eb-8feb-c74bedce501f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "\"\"\"  Show first two's row in dataset \"\"\"\n",
        "\n",
        "dftrain.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>subject</th>\n",
              "      <th>justification</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Says the Annies List political group supports ...</td>\n",
              "      <td>abortion</td>\n",
              "      <td>That's a premise that he fails to back up. Ann...</td>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When did the decline of coal start? It started...</td>\n",
              "      <td>energy,history,job-accomplishments</td>\n",
              "      <td>Surovell said the decline of coal \"started whe...</td>\n",
              "      <td>half-true</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           statement  ...      label\n",
              "0  Says the Annies List political group supports ...  ...      false\n",
              "1  When did the decline of coal start? It started...  ...  half-true\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHJmQW1XNO-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Convert Labels dataset to 0,1 by Call convertlabel Function , \n",
        "sentence to indeces by call transfer_sent Function\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "for i in range(dftrain.shape[0]):\n",
        "  dftrain.loc[i,'label']=convertlabel[dftrain.loc[i,'label']]\n",
        "  dftrain.loc[i,'statement']=transfer_sent(clean(dftrain.loc[i,'statement']),word_to_index)\n",
        "  dftrain.loc[i,'subject']=transfer_sent(clean(dftrain.loc[i,'subject']),word_to_index)\n",
        "  dftrain.loc[i,'justification']=transfer_sent(clean(dftrain.loc[i,'justification']),word_to_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ2rer47LEc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Take Labels two make only Target dataset and drop it in orignal dataset \"\"\"\n",
        "\n",
        "dftrainy=dftrain['label']\n",
        "\n",
        "dftrain=dftrain.drop(['label'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP-MvvSQU45O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Calc Max Lengths in every Columns by call retmax Function ,\n",
        "convert Data Frame to Matrix by convert2D Function\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "stmax,sumax,jumax=retmax(dftrain)\n",
        "Fulldata=np.array(convert2D([dftrain.statement,dftrain.subject,dftrain.justification],[410,30,1000]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGjc_T6CrFAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Split dataets to Training ,Validation and Testing Datasets \"\"\"\n",
        "\n",
        "dftrainy=list(dftrainy)\n",
        "training,trainingy=Fulldata[:10153],dftrainy[:10153]\n",
        "validation,validationy=Fulldata[10154:11422],dftrainy[10154:11422]\n",
        "testing,testingy=Fulldata[11423:],dftrainy[11423:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bInMSM2trKpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Convert every Datasets to Torch Datasets \"\"\"\n",
        "\n",
        "training=torch.from_numpy(training)\n",
        "trainingy = torch.tensor(trainingy) \n",
        "train_tensor = torch.utils.data.TensorDataset(training, trainingy)\n",
        "\n",
        "validation=torch.from_numpy(validation)\n",
        "validationy = torch.tensor(validationy) \n",
        "valid_tensor = torch.utils.data.TensorDataset(validation, validationy)\n",
        "\n",
        "testing=torch.from_numpy(testing)\n",
        "testingy = torch.tensor(testingy) \n",
        "test_tensor = torch.utils.data.TensorDataset(testing, testingy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT2PBtkUwPLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Create DataLoader to Every Datasets \"\"\"\n",
        "\n",
        "train_loader=torch.utils.data.DataLoader(dataset=train_tensor,batch_size=32,shuffle=True, num_workers=0)\n",
        "vali_loader=torch.utils.data.DataLoader(dataset=valid_tensor,batch_size=32,shuffle=True, num_workers=0)\n",
        "test_loader=torch.utils.data.DataLoader(dataset=test_tensor,batch_size=32,shuffle=True, num_workers=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2kIv7YUymWl",
        "colab_type": "code",
        "outputId": "e5275c00-16c1-4ec7-cb80-5644107dcf50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "\"\"\"\n",
        "object from NN Model\n",
        "and print it\n",
        "\"\"\"\n",
        "vocab_size = len(word_to_index)+1\n",
        "embedding_dim = 300\n",
        "net = NN(vocab_size, embedding_dim,torch.from_numpy(word_embedding))\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (embedding): Embedding(400001, 300)\n",
            "  (lstm): LSTM(903, 128, num_layers=2, batch_first=True, dropout=0.6)\n",
            "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ewj9UOVymBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Learning rate 0.001\n",
        "create Binary Cross Entropy Loss function\n",
        "Create Adam optimizer to optimization parameters of NN ( Embedding , Linear Layers )\n",
        "\n",
        "\"\"\"\n",
        "lr=0.001\n",
        "\n",
        "net.cuda()\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizer1 = torch.optim.Adam(net.lstm.parameters(), lr=lr)\n",
        "\n",
        "optimizer2 = torch.optim.Adam(net.fc.parameters(), lr=lr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd1XfvzUylwy",
        "colab_type": "code",
        "outputId": "8dac4e85-189f-43de-e5ff-660729afc9b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "\"\"\" 10 Number Epoch \"\"\"\n",
        "\n",
        "LtraininVis,LvalidVis=[],[]\n",
        "batch_size=32\n",
        "epochs = 25\n",
        "\n",
        "net.train() \n",
        "\n",
        "for e in range(epochs):\n",
        "\n",
        "  Taccuracy,Vaccuracy=[],[]\n",
        "  losses=[]\n",
        "  h = net.init_hidden(batch_size)\n",
        "  for inputs, labels in train_loader:\n",
        "\n",
        "    inputs, labels = inputs.cuda(), labels.cuda()  \n",
        "\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    net.zero_grad()\n",
        "    \n",
        "    output,h= net(inputs.long(),h)\n",
        "\n",
        "    Taccuracy.append(Accu(torch.round(output),labels))\n",
        "\n",
        "\n",
        "    loss = criterion(output.squeeze().float(), labels.float())\n",
        "\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(net.parameters(), 5)\n",
        "    optimizer1.step()\n",
        "    optimizer2.step()\n",
        "   \n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    net.eval()\n",
        "    val_losses = []\n",
        "    \n",
        "    val_h = net.init_hidden(batch_size)\n",
        "\n",
        "    for inputs, labels in vali_loader:\n",
        "\n",
        "      inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "      val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "      output,val_h= net(inputs.long(),val_h)\n",
        "\n",
        "      Vaccuracy.append(Accu(torch.round(output),labels))\n",
        "\n",
        "      val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "      val_losses.append(val_loss.item())\n",
        "\n",
        "    net.train()\n",
        "\n",
        "    LtraininVis.append(np.mean(losses))\n",
        "    LvalidVis.append(np.mean(val_losses))\n",
        "    print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "          \"Tarining Loss: {:.6f}...\".format(np.mean(losses)),\n",
        "          \"Val Loss: {:.6f}\".format(np.mean(val_losses)),\n",
        "          \"Val Accu:{:.6f}\".format(np.mean(Vaccuracy)),\n",
        "          \"Training Accu:{:.6f}\".format(np.mean(Taccuracy)))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/25... Tarining Loss: 0.680300... Val Loss: 0.682774 Val Accu:0.568438 Training Accu:0.563712\n",
            "Epoch: 2/25... Tarining Loss: 0.667177... Val Loss: 0.668037 Val Accu:0.599688 Training Accu:0.591675\n",
            "Epoch: 3/25... Tarining Loss: 0.658976... Val Loss: 0.677189 Val Accu:0.590469 Training Accu:0.602922\n",
            "Epoch: 4/25... Tarining Loss: 0.653848... Val Loss: 0.677264 Val Accu:0.579688 Training Accu:0.614605\n",
            "Epoch: 5/25... Tarining Loss: 0.649769... Val Loss: 0.653652 Val Accu:0.637656 Training Accu:0.613961\n",
            "Epoch: 6/25... Tarining Loss: 0.645486... Val Loss: 0.652580 Val Accu:0.628750 Training Accu:0.626802\n",
            "Epoch: 7/25... Tarining Loss: 0.640948... Val Loss: 0.648167 Val Accu:0.629531 Training Accu:0.629597\n",
            "Epoch: 8/25... Tarining Loss: 0.638872... Val Loss: 0.650564 Val Accu:0.634062 Training Accu:0.631409\n",
            "Epoch: 9/25... Tarining Loss: 0.631993... Val Loss: 0.651618 Val Accu:0.627656 Training Accu:0.645124\n",
            "Epoch: 10/25... Tarining Loss: 0.626038... Val Loss: 0.649618 Val Accu:0.633906 Training Accu:0.646609\n",
            "Epoch: 11/25... Tarining Loss: 0.617643... Val Loss: 0.660263 Val Accu:0.627812 Training Accu:0.658641\n",
            "Epoch: 12/25... Tarining Loss: 0.605309... Val Loss: 0.659706 Val Accu:0.633281 Training Accu:0.670881\n",
            "Epoch: 13/25... Tarining Loss: 0.599578... Val Loss: 0.645153 Val Accu:0.645000 Training Accu:0.675096\n",
            "Epoch: 14/25... Tarining Loss: 0.593295... Val Loss: 0.653539 Val Accu:0.633750 Training Accu:0.681342\n",
            "Epoch: 15/25... Tarining Loss: 0.579480... Val Loss: 0.658415 Val Accu:0.633594 Training Accu:0.694171\n",
            "Epoch: 16/25... Tarining Loss: 0.571184... Val Loss: 0.685418 Val Accu:0.630000 Training Accu:0.701192\n",
            "Epoch: 17/25... Tarining Loss: 0.562210... Val Loss: 0.673461 Val Accu:0.625156 Training Accu:0.708956\n",
            "Epoch: 18/25... Tarining Loss: 0.553645... Val Loss: 0.680573 Val Accu:0.634844 Training Accu:0.715584\n",
            "Epoch: 19/25... Tarining Loss: 0.542441... Val Loss: 0.710613 Val Accu:0.623281 Training Accu:0.722997\n",
            "Epoch: 20/25... Tarining Loss: 0.528664... Val Loss: 0.701662 Val Accu:0.615000 Training Accu:0.729734\n",
            "Epoch: 21/25... Tarining Loss: 0.523515... Val Loss: 0.694563 Val Accu:0.626250 Training Accu:0.731274\n",
            "Epoch: 22/25... Tarining Loss: 0.503972... Val Loss: 0.715556 Val Accu:0.619688 Training Accu:0.753341\n",
            "Epoch: 23/25... Tarining Loss: 0.493869... Val Loss: 0.716474 Val Accu:0.625312 Training Accu:0.757556\n",
            "Epoch: 24/25... Tarining Loss: 0.481884... Val Loss: 0.725451 Val Accu:0.615781 Training Accu:0.763943\n",
            "Epoch: 25/25... Tarining Loss: 0.467944... Val Loss: 0.745915 Val Accu:0.627969 Training Accu:0.773574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkpuEG1o4sF6",
        "colab_type": "code",
        "outputId": "d0601c84-008c-406a-b091-3a21922a1014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n",
        "ax1.plot(LtraininVis,label='Training Loss')\n",
        "ax1.plot(LvalidVis,label='Validation Loss')\n",
        "\n",
        "ax1.legend(frameon=False)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd19003d278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAFpCAYAAADUTv+7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud-mafcC5V_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}