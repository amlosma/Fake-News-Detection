{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake New TF-IDF.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smara97/FakeNews/blob/master/Fake_New_TF_IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ3Zr5r4lYzV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9cd879c0-1b05-40f7-cb1b-a067da91cfbf"
      },
      "source": [
        "from google.colab import  drive\n",
        "import re\n",
        "import string \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import Doc2Vec\n",
        "from gensim.models.doc2vec import LabeledSentence\n",
        "from gensim import utils\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SWo79SplzYG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "775ab649-d023-4b3a-eab5-2fcaaf7e7223"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5HeGhAhlzWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainingset=pd.read_csv(\"/content/drive/My Drive/Fake news competitive/finalstraingv1.csv\")\n",
        "trainingset=trainingset.drop([trainingset.columns[0]],axis=1)\n",
        "trainingset=trainingset.dropna()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yoq-R2y4lzTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean(text):\n",
        "  text=text.lower()\n",
        "  stp=set(stopwords.words(\"english\"))\n",
        "  placesp = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "  removech= re.compile('[^0-9a-z #+_]')\n",
        "  st=PorterStemmer()\n",
        "  text=re.sub(placesp,' ',text)\n",
        "  text=re.sub(removech,' ',text)\n",
        "  text=text.split()\n",
        "  text=[w for w in text if not w in stp]\n",
        "  text=[st.stem(w) for w in text]\n",
        "  text=\" \".join(text)\n",
        "  text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKIvpT40lzRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainingset['total']=trainingset['author']+' , '+trainingset['title']+' , '+trainingset['text']\n",
        "labels=trainingset['label']\n",
        "lbls=labels\n",
        "trainingset=trainingset.drop(['label'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CW54mIYlzNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(trainingset.shape[0]):\n",
        "  try:\n",
        "    trainingset.loc[i,'total']=clean(trainingset.loc[i,'total'])\n",
        "  except:\n",
        "    continue\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_btjyR3lzKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,5), max_df=1.0, min_df=0,token_pattern='(\\S+)')\n",
        "trainX= tfidf_vectorizer.fit_transform(trainingset.total)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlBR6qOglzHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_reversed_vocab = {i:word for word,i in tfidf_vectorizer.vocabulary_.items()}\n",
        "trainxx=trainX[:int(trainX.shape[0]*0.85)]\n",
        "testx=trainX[int(trainX.shape[0]*0.85)+1:]\n",
        "lablt=lbls[:int(trainX.shape[0]*0.85)]\n",
        "lablts=lbls[int(trainX.shape[0]*0.85)+1:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISynDomylzE1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "4e410355-69d7-4506-fbb9-4176248d3228"
      },
      "source": [
        "model = OneVsRestClassifier(LogisticRegression(penalty='l2', C=1.0))\n",
        "model.fit(trainxx, lablt)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                 dual=False, fit_intercept=True,\n",
              "                                                 intercept_scaling=1,\n",
              "                                                 l1_ratio=None, max_iter=100,\n",
              "                                                 multi_class='warn',\n",
              "                                                 n_jobs=None, penalty='l2',\n",
              "                                                 random_state=None,\n",
              "                                                 solver='warn', tol=0.0001,\n",
              "                                                 verbose=0, warm_start=False),\n",
              "                    n_jobs=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk_mYtUDlzCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=model.predict(testx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgfKGRtMly_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf6c5cd8-c97e-4edf-9463-3d7d00889361"
      },
      "source": [
        "num_co=(y_pred==lablts).sum()\n",
        "print(num_co/len(lablts))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7892167739072554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIBaXfycly-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0ac87dcf-be9a-4937-e32d-e5f917aa9998"
      },
      "source": [
        "author,title,text=\"Smara\",\"Assiut\",\"Assiut is a goverment in Egypt\"\n",
        "text=clean(author+' , '+' , '+title+' , '+text)\n",
        "tx=[]\n",
        "tx.append(text)\n",
        "tx=tfidf_vectorizer.transform(tx)\n",
        "ypred=model.predict(tx)\n",
        "if ypred == 0:\n",
        "  print(\"REAL :)\")\n",
        "else:\n",
        "  print(\"FAKE :(\")\n",
        "print(model.decision_function(tx))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REAL :)\n",
            "[-0.05555335]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe3-hhkcly8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}